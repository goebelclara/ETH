\section{Calculus}
\subsection*{Derivatives}
\emph{Rules} --- 
\begin{itemize}
    \item Sum rule: $\frac{\partial f + g}{\partial x} = \frac{\partial f}{\partial x} + \frac{\partial g}{\partial x}$
    \item Product rule: $\frac{\partial f \times g}{\partial x} = f \times \frac{\partial g}{\partial x} + g \times \frac{\partial f}{\partial x}$
    \item Chain rule: $\frac{\partial f(g)}{\partial x} = \frac{\partial f}{\partial g} \times \frac{g}{\partial x}$
    \item Scalar multipliers of the whole gradient can be ignored, even if the variable we are deriving wrt is included in this scalar
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Common derivatives} --- 
\begin{multicols}{2}
\begin{itemize}
    \item $\frac{\partial x^n}{\partial x} = nx^{n-1}$
    \item $\frac{\partial e^{kx}}{\partial x} = k \times e^{kx}$
    \item $\frac{\partial log(x)}{\partial x} = \frac{1}{x}$
    \item $\frac{\partial \sqrt{x}}{\partial x} = \frac{1}{2\sqrt{x}}$
    \item $\frac{\partial \sin(x)}{\partial x} = \cos(x)$
    \item $\frac{\partial \cos(x)}{\partial x} = -\sin(x)$
\end{itemize}
\end{multicols}

{\color{lightgray}\hrule height 0.001mm}

\emph{Partial and directional derivative} --- 
\begin{itemize}
    \item For a function that depends on $n$ variables $\{x_i\}_{i=2}^n$, partial derivative is slope of tangent line along direction of one specific variable $x_i$
    \item Directional derivative is slope of tangent line along direction of selected unit vector $\boldsymbol{u}$
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Gradient} --- 
\begin{itemize}
    \item Given scalar-valued function $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$, returns vector containing first-order partial derivatives:\\
    $\nabla_{\boldsymbol{x}} f: [\frac{\partial f}{\partial x_1} ... \frac{\partial f}{\partial x_n}]^\intercal$
    \item Gradient points in direction of greatest upward slope of f \item Magnitude of gradient equals rate of change when moving into direction of greatest upward slope 
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Hessian} --- 
\begin{itemize}
    \item Given scalar-valued function $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$, returns matrix containing second-order partial derivatives:\\
    $\mathcal{H} = \nabla_{\boldsymbol{x}}^2 f: \begin{bmatrix}
    \frac{\partial^2 f}{\partial x_1^2} & ... & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
    ... & ... & ... \\
    \frac{\partial^2 f}{\partial x_n \partial x_1} & ... & \frac{\partial^2 f}{\partial x_n^2}
    \end{bmatrix}$
    \item $\mathcal{H}$ is symmetric 
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Jacobian} --- 
\begin{itemize}
    \item Given vector-valued function $\boldsymbol{f}: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}$ with $\boldsymbol{f} = [f_1(\boldsymbol{x}), ..., f_m(\boldsymbol{x})]^\intercal$, returns matrix containing first-order partial derivatives:\\
    $\nabla_{\boldsymbol{x}} \boldsymbol{f}: \begin{bmatrix}
    \frac{\partial f_1}{\partial x_1} & ... & \frac{\partial f_1}{\partial x_n} \\
    ... & ... & ... \\
    \frac{\partial f_m}{\partial x_1} & ... & \frac{\partial f_m}{\partial x_n}
    \end{bmatrix} \in \mathbb{R}^{m \times n}$
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Matrix calculus rules} --- 
\begin{multicols}{2}
\begin{itemize}
    \item $\frac{\partial \boldsymbol{a}^\intercal\boldsymbol{x}}{\partial \boldsymbol{x}} = \boldsymbol{a}$
    \item $\frac{\partial \boldsymbol{x}^\intercal\boldsymbol{A}\boldsymbol{x}}{\partial \boldsymbol{x}} = (\boldsymbol{A} + \boldsymbol{A}^\intercal)\boldsymbol{x}$
    \item $\frac{\partial \boldsymbol{a}^\intercal\boldsymbol{A}\boldsymbol{b}}{\partial \boldsymbol{A}} = \boldsymbol{a}\boldsymbol{b}^\intercal$
    \item For symmetric $\boldsymbol{A}$: $\frac{\partial \boldsymbol{x}^\intercal\boldsymbol{A}\boldsymbol{x}}{\partial \boldsymbol{x}} = 2\boldsymbol{A}\boldsymbol{x}$
    \item For square $\boldsymbol{A}$: 
    \begin{itemize}
        \item $\frac{\partial \boldsymbol{a}^\intercal\boldsymbol{A}^{-1}\boldsymbol{b}}{\partial \boldsymbol{A}} = -(\boldsymbol{A}^\intercal)^{-1} \boldsymbol{a}\boldsymbol{c}^\intercal (\boldsymbol{A}^\intercal)^{-1}$
        \item $\frac{\partial log(|\boldsymbol{A}|)}{\partial \boldsymbol{A}} = (\boldsymbol{A}^\intercal)^{-1}$
    \end{itemize}
\end{itemize}
\end{multicols}

{\color{black}\hrule height 0.001mm}

\subsection*{Extrema}
\emph{Conditions for local minima and maxima} --- 
\begin{itemize}
    \item Point is a stationary point, i.e. first-order derivative = 0
    \item If Hessian is pd, it's a local minimum, if Hessian is nd, it's a local maximum, if Hessian is indefinite, it's a saddle point
    \item Local minima and maxima are the unique global minima and maxima in strictly convex functions resp. one of possibly infinitely many global minima and maxima in convex functions
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Convexity} --- 
\begin{itemize}
    \item For a convex function: 
    \begin{itemize}
        \item $f(\lambda x + (1-\lambda)y \leq \lambda f(x) + (1-\lambda) f(y)$ with $\lambda \in [0,1]$
        \item Hessian of stationary point(s) is psd
        \item Global minimum exists, but may not be unique
    \end{itemize}
    \item For a strictly convex function:
    \begin{itemize}
        \item $f(\lambda x + (1-\lambda)y < \lambda f(x) + (1-\lambda) f(y)$ with $\lambda \in [0,1]$
        \item Hessian of stationary point is pd
        \item Unique global minimum exists 
    \end{itemize}
    \item Sum of convex functions $f_2(x) + f_1(x)$ is also convex, sum of convex and strictly convex function is strictly convex
    \item Chain of convex functions $f_2(f_1(x))$, where outer function $f_2(x)$ is increasing, is also convex
    \item Scalar multiple of convex function $\lambda f(x)$, where $\lambda \geq 0$, is also convex
    \item Any norm is convex
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Nature of optimum} --- 
What does Hessian and function look like?
\begin{itemize}
    \item If Hessian is pd and loss function is strictly convex, stationary point is a global minimum, and there is a unique solution
    \item If Hessian is psd and loss function is convex, stationary point is a global minimum, and there may be a geometrically unique or infinitely many solutions
    \item If Hessian is p(s)d but loss function is not convex, stationary point may be a local minimum and there may be a geometrically unique or infinitely many solutions
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Optimization approach} --- 
Is function differentiable, continuous, and are relevant terms invertible?
\begin{itemize}
    \item If yes, analytically solvable
    \item If no, numerically solvable (e.g. via gradient descent)
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Constrained optimization} --- 
\begin{itemize}
    \item \emph{Lagrangian function}: $\mathcal{L}(\boldsymbol{x},\lambda) = f(\boldsymbol{x}) + \lambda g(\boldsymbol{x})$, where $g(\boldsymbol{x})$ is an $(m-1)$ dimensional constraint surface and $\lambda$ is the Lagrange multiplier
    \item$\nabla_{\boldsymbol{x}} \mathcal{L} = \nabla_{\boldsymbol{x}} f(\boldsymbol{x}) + \lambda \nabla_{\boldsymbol{x}} g(\boldsymbol{x})$
    \item$\nabla_{\lambda} \mathcal{L} = g(\boldsymbol{x})$
    \item Solution is feasible if it fulfills constraints and optimal, if no other feasible solution produces a lower error
    \item Minimizing over Lagrangian $\mathcal{L}(\boldsymbol{x},\lambda) = f(\boldsymbol{x}) + \lambda g(\boldsymbol{x})$ corresponds to minimizing log-loss:
    \begin{itemize}
        \item $\hat{\boldsymbol{x}} = \arg\max_\boldsymbol{x} p(\boldsymbol{D} |\boldsymbol{x}) \rho(\boldsymbol{x}) $ 
        \item $= \arg\min_\boldsymbol{x} (- log p(\boldsymbol{D} |\boldsymbol{x}) + k(\boldsymbol{x}))$
        \item where $k(\boldsymbol{x}) = -log \rho(\boldsymbol{x})$
    \end{itemize}
    $\mathcal{L}(\boldsymbol{x},\lambda) = f(\boldsymbol{x}) + \lambda g(\boldsymbol{x})$
\end{itemize}\\
For equality constraints: Minimize $f(\boldsymbol{x})$ subject to $g(\boldsymbol{x}) = 0$
\begin{itemize}
    \item Gradient of $f(\boldsymbol{x})$ must be orthogonal to constraint surface, otherwise (if it points into any direction along the constraint surface) $f(\boldsymbol{x})$ could still decrease for movements along the constraint surface
    \item On the constraint surface, $g(\boldsymbol{x})$ is a constant, so moving along any direction on the constraint surface has a directional derivative of 0. Since the gradient of $g(\boldsymbol{x})$ points into the direction of steepest ascent, it must be orthogonal to the constraint surface, otherwise (if it points into any direction along the constraint surface) $g(\boldsymbol{x})$ would not be constant on the constraint surface
    \item Then, gradients are parallel at optimum: $\nabla_{\boldsymbol{x}} f(\boldsymbol{x^*}) = \lambda \times \nabla_{\boldsymbol{x}} g(\boldsymbol{x^*})$
    \item To find $\boldsymbol{x^*}$ and $\lambda^*$: 
    \begin{itemize}
        \item $\nabla_{\boldsymbol{x}} \mathcal{L} = 0$, expresses parallelity condition at minimum $\boldsymbol{x^*}$
        \item $\nabla_{\lambda} \mathcal{L} = 0$, expresses constraint
        \item This is an unconstrained optimization problem
    \end{itemize}
    \item Optimum $\boldsymbol{x^*}$ and $\lambda^*$ represents a saddle point of $\mathcal{L}$
\end{itemize}\\
For inequality constraints: Minimize $f(\boldsymbol{x})$ subject to $g(\boldsymbol{x}) \leq 0$ 
\begin{itemize}
    \item If $\boldsymbol{x^*}$ lies in $g(\boldsymbol{x}) < 0$, constraint is inactive
    \item Otherwise, if $\boldsymbol{x^*}$ lies in $g(\boldsymbol{x}) = 0$, constraint is active:
    \begin{itemize}
        \item Gradient of $f(\boldsymbol{x})$ must point towards $g(\boldsymbol{x}) < 0$ region, otherwise (if it would point away from $g(\boldsymbol{x}) < 0$ region) the optimum would lie in this region
        \item Then, gradients are anti-parallel at optimum: $\nabla_{\boldsymbol{x}} f(\boldsymbol{x^*}) = -\lambda \times \nabla_{\boldsymbol{x}} g(\boldsymbol{x^*})$
    \end{itemize}
    \item To find $\boldsymbol{x^*}$ and $\lambda^*$: 
    \begin{itemize}
        \item $\nabla_{\boldsymbol{x}} \mathcal{L} = 0$ subject to \emph{Karush Kuhn Tucker conditions}:
        \begin{itemize}
            \item $g(\boldsymbol{x}) \leq 0$
            \item $\lambda \geq 0$
            \item \emph{Complementary slackness condition}: $\lambda g(\boldsymbol{x}) = 0$, with $\lambda = 0, g(\boldsymbol{x}) < 0$ for inactive constraints and $\lambda > 0, g(\boldsymbol{x}) = 0$ for active constraints
        \end{itemize}
        \item $\nabla_{\lambda} \mathcal{L} = 0$ given complementary slackness condition
        \item This is not an unconstrained optimization problem, but can be solved via duality
    \end{itemize}
    \item Optimum $\boldsymbol{x^*}$ and $\lambda^*$ represents a saddle point of $\mathcal{L}$
\end{itemize}\\
For multiple constraints: Minimize $f(\boldsymbol{x})$ subject to $m$ inequality constraints $\{g^{(i)}(\boldsymbol{x}) \leq 0\}_{i=1}^m$ and $p$ equality constraints $\{h^{(j)}(\boldsymbol{x}) = 0\}_{j=1}^p$ 
\begin{itemize}
    \item Then, Lagrangian is given by: $\mathcal{L}(\boldsymbol{x},\boldsymbol{\lambda},\boldsymbol{\mu}) = f(\boldsymbol{x}) + \sum_{i=1}^m \mu^{(i)} g^{(i)}(\boldsymbol{x}) + \sum_{j=1}^p \lambda^{(j)} h^{(j)}(\boldsymbol{x})$
    \item Then, general solution $\boldsymbol{x^*},\boldsymbol{\lambda^*},\boldsymbol{\mu^*}$ is given by: $\nabla_{\boldsymbol{x}} \mathcal{L} = 0$ subject to:
    \begin{itemize}
        \item $\{g^{(i)}(\boldsymbol{x}) \leq 0\}_{i=1}^m$ and $\{h^{(j)}(\boldsymbol{x}) = 0\}_{j=1}^p$ 
        \item $\{\mu^{(i)} \geq 0\}_{i=1}^m$
        \item $\{\mu^{(i)}g^{(i)}(\boldsymbol{x}) = 0\}_{i=1}^m$
    \end{itemize}
\end{itemize}\\
\emph{Primal problem}:
\begin{itemize}
    \item $\textrm{min}_{\boldsymbol{x}} [\textrm{max}_{\boldsymbol{\lambda},\boldsymbol{\mu}} \mathcal{L}]$
    \item $\textrm{max}_{\boldsymbol{\lambda},\boldsymbol{\mu}} \mathcal{L} = f(\boldsymbol{x}) + \textrm{max}_{\boldsymbol{\lambda},\boldsymbol{\mu}} [\sum_{i=1}^m \mu^{(i)} g^{(i)}(\boldsymbol{x}) + \sum_{j=1}^p \lambda^{(j)} h^{(j)}(\boldsymbol{x})]$
    \item Second term gives rise to barrier function:
    \begin{itemize}
        \item $= 0$ subject to constraints being met, given complementary slackness condition for inequality constraints and $h^{(j)}(\boldsymbol{x}) = 0$ for equality constraints, which implies that dual problem becomes $\textrm{min}_{\boldsymbol{x}}(f(\boldsymbol{x}))$
        \item $= \infty$ otherwise, which implies that primal problem cannot be solved
    \end{itemize}
    \item Let $f(\boldsymbol{x}^*)$ be the solution to the primal problem
\end{itemize}
Solving inequality constraints via duality: 
\begin{itemize}
    \item \emph{Dual problem}: $ \textrm{max}_{\boldsymbol{\lambda},\boldsymbol{\mu}} [\textrm{min}_{\boldsymbol{x}} \mathcal{L}]$
    \item Let $\textrm{min}_{\boldsymbol{x}} \mathcal{L} = \theta(\boldsymbol{\lambda},\boldsymbol{\mu})$
    \item Let $\theta(\boldsymbol{\lambda}^*,\boldsymbol{\mu}^*)$ be the solution to the dual problem
\end{itemize}
\emph{Weak duality}:
\begin{itemize}
    \item Weak duality always holds and gives a lower bound of minimum of primal problem
    \item Given minimax theorem, $f(\boldsymbol{x}^*) = \textrm{min}_{\boldsymbol{x}} [\textrm{max}_{\boldsymbol{\lambda},\boldsymbol{\mu}} \mathcal{L}] = \textrm{min}_{\boldsymbol{x}}(f(\boldsymbol{x})) \textrm{ (provided barrier function) } \geq \textrm{max}_{\boldsymbol{\lambda},\boldsymbol{\mu}} [\textrm{min}_{\boldsymbol{x}} \mathcal{L}] = \theta(\boldsymbol{\lambda}^*,\boldsymbol{\mu}^*)$
    \item $\textrm{min}_{\boldsymbol{x}} \mathcal{L}$ is an unconstrained optimization problem 
    \item $\textrm{max}_{\boldsymbol{\lambda},\boldsymbol{\mu}} [\textrm{min}_{\boldsymbol{x}} \mathcal{L}]$ is a concave maximization problem 
\end{itemize}
\emph{Strong duality}:
\begin{itemize}
    \item Strong duality holds under certain conditions, for example \emph{Slater's condition} if there exists a solution that strictly fulfills all constraints $\{g^{(i)}(\boldsymbol{x}) < 0\}_{i=1}^m$ and $\{h^{(j)}(\boldsymbol{x}) < 0\}_{j=1}^p$
    \item Then, $f(\boldsymbol{x}^*) = \textrm{min}_{\boldsymbol{x}} [\textrm{max}_{\boldsymbol{\lambda},\boldsymbol{\mu}} \mathcal{L}] = \textrm{max}_{\boldsymbol{\lambda},\boldsymbol{\mu}} [\textrm{min}_{\boldsymbol{x}} \mathcal{L}]= \theta(\boldsymbol{\lambda}^*,\boldsymbol{\mu}^*)$
    \item $\textrm{min}_{\boldsymbol{x}} \mathcal{L}$ can be solved for general solution $\boldsymbol{x^*}$ in terms of $\boldsymbol{\lambda},\boldsymbol{\mu}$
    \item Plug $\boldsymbol{x^*}$ back into $\mathcal{L}$ and maximize to find solutions $\boldsymbol{\lambda^*},\boldsymbol{\mu^*}$
    \item Specify $\boldsymbol{x^*}$ based on $\boldsymbol{\lambda^*},\boldsymbol{\mu^*}$
\end{itemize}

{\color{black}\hrule height 0.001mm}

\subsection*{Integrals}
\emph{Indefinite integral} --- 
\begin{itemize}
    \item $F(x) = \int f(x) dx$
    \item $F'(x) = f(x)$
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Definite integral} --- 
\begin{itemize}
    \item $F(b) - F(a) = \int_a^b f(x) dx$
    \item $F'(x) = f(x)$
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Common integrals} --- 
\begin{itemize}
    \item $f(x) = x^n \rightarrow F(x) = \frac{x^{n+1}}{n+1}$ for $n \neq 1$
    \item $f(x) = \frac{1}{x} \rightarrow F(x) = log(x)$
    \item $f(x) = e^x \rightarrow F(x) = e^x$
\end{itemize}