\section{Long-Short-Term Memory (LSTM)}
\subsection*{Description}
\emph{Description} --- 
\begin{itemize}
    \item Can deal with sequential data and the persistence of information over time
    \item Can be seq-to-seq, seq-to-vec, or vec-to-seq
    \item Can be unidirectional or bidirectional
\end{itemize}

{\color{black}\hrule height 0.001mm}

\subsection*{Formulation}
\emph{Formulation} --- 
\begin{itemize}
    \item Model architecture: 
    \begin{itemize}
        \item Input layer
        \item Hidden layer resp. memory cell: 
        \begin{itemize}
            \item Short-term state $\boldsymbol{h}_t$, long-term state $\boldsymbol{c}_t$
            \item Cell output $\boldsymbol{y}_t$
        \end{itemize}
        \item Output layer
    \end{itemize}
    \item Forget gate:
    \begin{itemize}
        \item Sigmoid layer
        \item Serves to decide which information to keep from previous cell state, $1:$ retain, $0$: forget
        \item $\boldsymbol{f}_t = \sigma (\boldsymbol{w}_f \cdot [ \boldsymbol{h}_{t-1}, \boldsymbol{x}_t ] + \boldsymbol{b}_f $ where $\boldsymbol{w}_f = \begin{bmatrix}
        \boldsymbol{w}_{xf} & \textrm{= connection weight for } x_t \\
        \boldsymbol{w}_{hf} & \textrm{= connection weight for } h_{t-1} \\
        \end{bmatrix}$
    \end{itemize}
    \item Input gate:
    \begin{itemize}
        \item Two stages:
        \begin{itemize}
            \item Sigmoid layer, determines if values are updated, $1:$ update values, $0$: do not update values
            \item Tanh layer, creates vector of new candidate values that could be added to the cell state
        \end{itemize}
        \item Serves to decide which information will be stored in the cell state
        \item $\boldsymbol{i}_t = \sigma (\boldsymbol{w}_i \cdot [ \boldsymbol{h}_{t-1}, \boldsymbol{x}_t ] + \boldsymbol{b}_i $ where $\boldsymbol{w}_i = \begin{bmatrix}
        \boldsymbol{w}_{xi} & \textrm{= connection weight for } x_t \\
        \boldsymbol{w}_{hi} & \textrm{= connection weight for } h_{t-1} \\
        \end{bmatrix}$
        \item $\boldsymbol{\tilde{c}}_t = tanh (\boldsymbol{w}_{\tilde{c}} \cdot [ \boldsymbol{h}_{t-1}, \boldsymbol{x}_t ] + \boldsymbol{b}_c $ where $\boldsymbol{w}_{\tilde{c}} = \begin{bmatrix}
        \boldsymbol{w}_{x{\tilde{c}}} & \textrm{= connection weight for } x_t \\
        \boldsymbol{w}_{h{\tilde{c}}} & \textrm{= connection weight for } h_{t-1} \\
        \end{bmatrix}$
    \end{itemize}
    \item Cell state:
    \begin{itemize}
        \item Two stages:
        \begin{itemize}
            \item Calculate what is left from previous cell state after forget care
            \item Calculate what we need to add to cell state after input gate
        \end{itemize}
        \item Serves to update old cell state into new cell state
        \item $\boldsymbol{c}_t = \boldsymbol{f}_t \otimes \boldsymbol{c}_{t-1} + \boldsymbol{i}_t \otimes \boldsymbol{\tilde{c}}_{t}$ where $\otimes$ is element-wise multiplication
    \end{itemize}
    \item Output gate:
    \begin{itemize}
        \item Three stages:
        \begin{itemize}
            \item Sigmoid layer, determines which part of cell state to output
            \item Tanh layer, activates cell state values
            \item Multiply activated cell state and output gate values to get $\boldsymbol{h}_t$
        \end{itemize}
        \item Serves to output $\boldsymbol{h}_t$ for next time step, which is a filtered version of cell state $\boldsymbol{c}_t$
        \item $\boldsymbol{o}_t = \sigma (\boldsymbol{w}_o \cdot [ \boldsymbol{h}_{t-1}, \boldsymbol{x}_t ] + \boldsymbol{b}_o $ where $\boldsymbol{w}_o = \begin{bmatrix}
        \boldsymbol{w}_{xo} & \textrm{= connection weight for } x_t \\
        \boldsymbol{w}_{ho} & \textrm{= connection weight for } h_{t-1} \\
        \end{bmatrix}$
        \item $\boldsymbol{h}_t = \boldsymbol{o}_t \otimes tanh(\boldsymbol{c}_t)$
    \end{itemize}
\end{itemize}

{\color{black}\hrule height 0.001mm}

\subsection*{Optimization}
\emph{Parameters} --- Find parameters $\theta$, which are shared across time steps

{\color{lightgray}\hrule height 0.001mm}

\emph{Objective function} --- 
\begin{itemize}
    \item Maximize log likelihood
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Optimization} ---
\begin{itemize}
    \item Perform \emph{forward pass} with randomly initialized parameters, to calculate loss
    \item Perform \emph{backpropagation through time}, to calculate gradient
    \item Perform gradient descent to find best weights 
\end{itemize}