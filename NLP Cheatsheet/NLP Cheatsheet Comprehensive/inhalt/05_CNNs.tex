\section{Convolutional Neural Networks (CNNs)}
\subsection*{Formulation}
\emph{Formulation} --- 
\begin{itemize}
    \item Model architecture: 
    \begin{itemize}
        \item Input: Composed of channels (e.g. R with 3 channels)
        \item \emph{Channel}: Sublayer in input and output, composed of pixels
        \item \emph{Convolutional layer}: Composed of feature maps
        \item \emph{Feature map}: Sublayer in convolutional layer, composed of neurons, each neuron is generated by applying filter to all receptive fields across all sublayers in lower layer, weights and biases shared across all neurons in feature map
        \item \emph{Receptive field}: Group of neurons in lower layer, that single neuron in higher layer is connected to, size $f_h \times f_w$
        \item \emph{Filter resp. convolutional kernel}: Weights applied to all receptive fields across all sublayers in lower layer, size $K \times K$
        \item \emph{Zero padding}: Padding applied to retain same dimensions in each layer, size $\frac{f_h - 1}{2}$ resp. $\frac{f_w - 1}{2}$
        \item \emph{Stride}: By how many neurons receptive field shifts, size $s_h \times s_w$, if stride $> 1$, spatial dimensions in subsequent layer decrease (\emph{convolution}), if stride $< 1$, spatial dimensions increase (\emph{deconvolution})
    \end{itemize}
    \item Output of neuron in layer $n$, given previous layer $n-1$: \\
    $z_{i,j,k} = b_k + \sum_{f_n} \sum_{f_w} \sum_{f_n'} x_{i',j',k'} \cdot w_{u,v,k',k}$, i.e. sum of element-wise matrix product over all receptive fields and all feature maps, where
    \begin{itemize}
        \item $z_{i,j,k}$ is the output of neuron in row $i$ and column $j$ on feature map $k$ in layer $n$
        \item $f_n$ and $f_w$ are dimensions of the receptive field in layer $n-1$
        \item $f_n'$ is the number of feature maps in layer $n-1$
        \item $x_{i',j',k'}$ is the output of neuron in row $i'$ and column $j'$ on feature map $k'$ in layer $n-1$
        \item $i' = i \times \textrm{stride}_h + u - \textrm{padding}_h$
        and $j' = j \times \textrm{stride}_w + v - \textrm{padding}_w$
        \item $w_{u,v,k',k}$ is the connection weight between any neuron on feature map $k$ in layer $n$ and its input at $u,v$ on feature map $k'$
        \item $u,v \in \Delta_K$ are possible shifts allowed by kernel
    \end{itemize}
    \item Output of neurons in layer $n$, given previous layer $n-1$: \\
    $\boldsymbol{z}_k = b_k + \sum_{f_n} \sum_{f_w} \sum_{f_n'} \boldsymbol{W}_{k',k} \boldsymbol{X}_{k'}$
    \item Output size in layer $n$, given previous layer $n-1$: $H' = \frac{H + 2p - K}{\textrm{stride}_h} + 1$ and
    $W' = \frac{W + 2p - K}{\textrm{stride}_w} + 1$
\end{itemize}