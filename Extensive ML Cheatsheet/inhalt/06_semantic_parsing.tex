\section{Semantics | Semantic Parsing}
\subsection*{Description}
\emph{Task} --- Assign semantic structure, i.e. logical form, to a sentence

{\color{lightgray}\hrule height 0.001mm}

\emph{Description} ---
\begin{itemize}
    \item Principle of compositionality:
    \begin{itemize}
        \item The meaning of a complex expression is a function of the meanings of that expression's constituent parts
        \item $\rightarrow$ We can syntactically parse a sentence
        \item $\rightarrow$ We can then construct the semantic representation bottom-up
    \end{itemize}
    \item Applying the principle of compositionality:
    \begin{itemize}
        \item Syntactic rule, e.g. $\textrm{S} \to \textrm{NP VP}$
        \item Induces semantic rule, e.g. $\textrm{s.sem} \to \textrm{VP.sem} (\textrm{NP.sem})$: to get the semantic representation of sentence $s$, we apply the semantic representation of the verb phrase (a function) to the semantic representation of the noun phrase
    \end{itemize}
\end{itemize}

{\color{black}\hrule height 0.001mm}

\subsection*{Lambda Calculus}
\emph{Basics} ---
\begin{itemize}
    \item Basic terms: Variables $x, y, z, \dots$
    \begin{itemize}
        \item Free variables: Do not occur in the scope of any abstraction that holds its name
        \item Otherwise, bound variables: Bound by the abstraction with the smallest scope
        \item E.g. $((\textcolor{orange}{\lambda x[}.\textcolor{red}{\lambda y[}.(\textcolor{orange}{x} ((\textcolor{blue}{\lambda x.[x]} \textcolor{orange}{x}) \textcolor{red}{y}))\textcolor{red}{]}\textcolor{orange}{]} \textcolor{green}{\lambda x.[x]}) z)$ where
        \begin{itemize}
            \item $z$ is unbound
            \item Other variables are bound by same-colored abstractions
            \item Scopes of abstractions are indicated by square brackets
        \end{itemize}
    \end{itemize}
    \items New terms can be constructed using $2$ recursive rules:
    \begin{itemize}
        \item 1) Abstraction:
        \begin{itemize}
            \item If $M$ is a term, $N$ is a term, and $x$ is a variable:
            \begin{itemize}
                \item $\lambda x$ is an abstraction
                \item $\lambda x.M$ is a function that takes $x$ as input and produces $M$ as output by replacing every free occurrence of $x$ in $M$ with whatever the function is applied to (e.g. $N$)
                \item $\lambda x.M N$ is a function applied to $N$
                \item We denote the output of $\lambda x.M N$ as $M[x := N]$
                \item In the output of $\lambda x.M N$, only $M[x := N]$ remains, and $\lambda x.$ and $N$ disappear
            \end{itemize}
            \item Scope of abstraction: The scope of abstraction $\lambda x$ in expression $\lambda x.M$ is $M$
        \end{itemize}
        \item 2) Application: If $M$ and $N$ are terms, $(MN)$ is a term
    \end{itemize}
    \item Enriched lambda calculus offers additional components:
    \begin{itemize}
        \item Logical constants: Represent objects (e.g. Boston) and relationships (e.g. likes)
        \item Variables:
        \begin{itemize}
            \item Undetermined logical constants
            \item Objects are represented in lowercase as $x, y, z, \dots$ and are input to $\lambda x.f(x)$)
            \item Relations are represented in uppercase as $P, Q, R, \dots$ and are input to $\lambda P.P(\dots)$
        \end{itemize}
        \item Literals: Formed by applying relations to objects (e.g. likes(Alex, y), $P(x, y)$)
        \item Every relation symbol has an \emph{arity} that determines the number of objects it relates
        \item Logical connectives and quantifiers: $\exists, \forall, \neg, \land, \lor$
    \end{itemize}
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Example} ---
\hl{INSERT IMAGE 1}

{\color{lightgray}\hrule height 0.001mm}

\emph{Alpha conversion} ---
\begin{itemize}
    \item Process of renaming a variable in a lambda term
    \item We can rename a variable in an abstraction together with all its occurrences in the scope of the abstraction, provided it remains bound to the same abstraction after renaming
    \item If the variable remains bound to the same abstraction, and no new variables become bound to the abstraction, the renaming is valid
    \item E.g. 
    $\lambda x.\lambda y.(x((\lambda x. x x) y )) \to \lambda z. \lambda y. (z((\lambda x. x z) y))$ is valid\\
    $\lambda x.(xy) \to \lambda y.(yy)$ is not valid, since $y$ was free before and is now bound
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Beta reduction} ---
\begin{itemize}
    \item Process of applying one lambda term to another: $(\lambda x.M)N$
    \item We can apply one lambda term to another if the free variables in $N$ remain free in $M[x := N]$
    \item If this is not the case, first apply alpha-conversion to $M$
    \item Termination issue: Repeatedly applying beta reductions may not terminate
    \item E.g. $\lambda y.(z((\lambda x.\textcolor{blue}{\boldsymbol{x}}\textcolor{orange}{z})y)) \to \lambda y.(z(\textcolor{red}{z}y))$\\
    $(\lambda x.\textcolor{blue}{\lambda y.(\boldsymbol{x}((\lambda x.x\boldsymbol{x})y))}\textcolor{orange}{z}) \to \lambda y.(\textcolor{red}{z}((\lambda x.x\textcolor{red}{z})y))$
    where
    \begin{itemize}
        \item $\textcolor{blue}{blue}$ corresponds to $M$
        \item $\textcolor{orange}{orange}$ corresponds to $N$
        \item $\textcolor{red}{red}$ corresponds to $M[x := N]$
        \item $\boldsymbol{bold}$ corresponds to free variables in $M$
    \end{itemize}
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Equivalence} --- Two lambda terms are equivalent if they can be obtained from each other via a series of $\alpha$- and $\beta$-conversions

{\color{black}\hrule height 0.001mm}

\subsection*{Combinatory Logic resp. SK-Calculus}
\begin{itemize}
    \item Alternative to lambda calculus
    \item Does not use abstractions
    \item Basic terms:
    \begin{itemize}
        \item Variables: $x, y, z, \dots$
        \item Primitive functions resp. combinators: $I, J, K, \dots$
        \begin{itemize}
            \item $I$ combinator: Identity function: $Ix = x$
            \item $K$ combinator: Constant function that always outputs $x$: $Kxy = ((Kx)y) = x$
            \item $S$ combinator: $Sxyz = (xz(yz)) = ((xz)(yz)$
        \end{itemize}
    \end{itemize}
    \item Terms are recursively constructed via application: If $M$ and $N$ are terms, $(MN)$ is a term
    \item Additional combinators:
    \begin{itemize}
        \item $B$ combinator resp. composition combinator: Composition function: $Bxyz = (x(yz))$
        \item $C$ combinator: $Cxyz = ((xz)y)$
        \item $T$ combinator resp. type-raising combinator: $Txy = yx$
    \end{itemize}
    \item Parentheses are left-associative, e.g. $(Kxyz) = (((Kx)y)z)$
    \item Reduction: 
    \begin{itemize}
        \item $SKK$ and $I$ are extensionally equivalent: $S(KK)x = SKKx = K x(K x) = x$
        \item Therefore, the $SK$ basis is complete, and we don't need $I$ operator
    \end{itemize}
\end{itemize}

{\color{black}\hrule height 0.001mm}

\subsection*{Transforming Lambda Calculus into SK-Calculus}
Apply recursively defined transformation $T$:
\begin{enumerate}
    \item $T(x) = x$ for every variable $x$
    \item $T[(E_1E_2)] = (T[E_1]T[E_2])$ for all lambda terms $E_1$ and $E_2$
    \item $T[\lambda x.E] = (KT[E])$ for every lambda term where $x$ is bound
    \item $T[\lambda x.x] =  (SKK) = I$
    \item $T[\lambda x.\lambda y.E] = T[\lambda x.T[\lambda y.E]]$ for every lambda term $E$ where $x$ is free
    \item $T[\lambda x.(E_1E_2)] = (ST[\lambda x.E_1]T[\lambda x.E_2])$ for all lambda terms $E_1, E_2$ where $x$ is free in at least one of the two terms
\end{enumerate}

{\color{black}\hrule height 0.001mm}

\subsection*{Linear Indexed Grammar resp. Combinatory Categorial Grammars (CCG)}
\emph{Features} --- 
\begin{itemize}
    \item Lexicalized grammar: Every word is associated with a syntactic category (including information about syntax and semantics) that defines how it combines with other words
    \item Compositionality: Semantic representation of a sentence is built in tandem with its syntactic derivation
    \item Flexible word order: Supports languages with complex or free word order (e.g. cross-serial dependencies, long-distance dependencies, coordination)
    \item The latter two are advantages over context-free grammars
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Linear Indexed Grammar $\langle \mathcal{N}, S, \mathcal{I}, \Sigma, \mathcal{R} \rangle$} --- 
\begin{itemize}
    \item $\mathcal{N}$: Set of non-terminal symbols $N_1, N_2, N_3, \dots$
    \item $S$: Start non-terminal
    \item $\mathcal{I}$: Finite set of indices $f, g, h, \dots$
    \item $\Sigma$: Alphabet of terminal symbols $a_1, a_2, a_3, \dots$
    \item $\mathcal{R}$: Set of production rules of the following forms:
    \begin{itemize}
        \item $N[\sigma] \to \alpha M[\sigma]\beta$
        \item $N[\sigma] \to \alpha M[f\sigma]\beta$
        \item $N[f\sigma] \to \alpha M[\sigma]\beta$
        \item Where
        \begin{itemize}
            \item $N$ and $M$ are non-terminals
            \item $\alpha$ and $\beta$ are strings of terminals and non-terminals
            \item $\sigma$ is the stack passed to exactly one non-terminal on RHS
        \end{itemize}
    \end{itemize}
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Combinatory Categorial Grammar $\langle \mathcal{V}_T, \mathcal{V}_N, S, f, \mathcal{R} \rangle$} --- 
\begin{itemize}
    \item $\mathcal{V}_T$: Set of terminals
    \item $\mathcal{V}_N$: Atomic categories: Set of non-terminals
    \item $S$: Start non-terminal $\in \mathcal{V}_N$
    \item $f: \mathcal{V}_T \to \mathcal{C}(\mathcal{V}_N)$: Lexicon: Function that maps elements of $\mathcal{V}_T \cup \{\varepsilon\}$ to finite subsets of $\mathcal{C}(\mathcal{V}_N)$, where $\mathcal{C}(\mathcal{V}_N)$ is the set of categories
    \item $\mathcal{R}$: Set of production rules, e.g. application
\end{itemize}
Composed of $2$ parts:
\begin{itemize}
    \item Lexicon: Associates words with categories, which encode the structure\\
    $\rightarrow$ Difference to context-free grammar, which encodes the structure in the rules
    \begin{itemize}
        \item Atomic categories: 
        \begin{itemize}
            \item Category of complete constituents
            \item E.g. $\textrm{Harry} := \boldsymbol{NP}$
        \end{itemize}
        \item Complex categories:
        \begin{itemize}
             \item Built recursively from atomic categories via operators
            \item Category of incomplete constituents
            \item Function that specifies the type of result and type and direction of its arguments
            \item E.g. $\textrm{walks} := (\textbf{S} \backslash \textbf{NP})$.
        \end{itemize}
        \item Set of categories $\mathcal{C}(\mathcal{V}_N)$ is the smallest set such that:
        \begin{itemize}
            \item If $C \in \mathcal{V}_N$, then $C \in \mathcal{C}(\mathcal{V}_N)$
            \item If $C_1, C_2 \in \mathcal{V}_N$, then $(C_1 / C_2) \in \mathcal{C}(\mathcal{V}_N)$ and $(C_1 \backslash C_2) \in \mathcal{C}(\mathcal{V}_N)$
        \end{itemize}
        \item Every category can be written in the form $X = A \mid_m X_m \dots \mid_1 X_1, \quad m \geq 0$ where
        \begin{itemize}
            \item $A$: Atomic category = target of $X$
            \item $X_1, \dots, X_m$: Arbitrary categories = arguments of $X$
            \item $\mid$ = Backward or forward slash
            \item $m$ = Arity of $X$
        \end{itemize}
    \end{itemize}
    \item Rules:
    \begin{itemize}
        \item Specify how categories can be combined into other categories
        \item Pattern: $X / Y \quad Y \to X$ where $X / Y$ is function, $Y$ is argument, and $X$ is result
        \item Types of rules:
        \begin{itemize}
            \item Function application:
            \begin{itemize}
                \item Forward application: $(>)$: If a category expects an argument to the right of $(X / Y)$ and argument $Y$ is available, they combine to form $X$: $X / Y \quad Y \to X$
                \item Backward application: $(<)$: If a category expects an argument to the left of $(X \backslash Y)$ and argument $Y$ is available, they combine to form $X$: $Y \quad X \backslash Y\to X$
                \item AB grammar resp. basic categorical grammar resp. pure categorical grammar:
                \begin{itemize}
                    \item CCGs that only have application rules
                    \item Have power of CFG:
                    $
                    A \to a \text{ in CCG} \equiv A \to a \text{ in CFG}
                    $\\
                    $
                    A \to (A / C) C \text{ in CCG} \equiv A \to BC \text{ in CFG}
                    $
                \end{itemize}
            \end{itemize}
            \item Function composition
            \begin{itemize}
                \item Two functions combine to form a single function: $f, g \to f \circ g$
                \item Forward composition: $((B_>$: $(X / Y) \quad (Y / Z) \to (X / Z)$
                \item Backward composition: $((B_<)$: $(Y \backslash Z) \quad (X \backslash Y) \to (X \backslash Z)$
            \end{itemize}
            \item Higher-order rules:
            \begin{itemize}
                \item Forward: $(>^n)$
                $
                X/Y \ Y \mid_n Y_n ... \mid_1 Y_1 \to X \mid_n Y_n ... \mid_1 Y_1 
                $
                \item Backward: $(<^n)$
                $
                Y \mid_n Y_n ... \mid_1 Y_1 \ X \backslash Y \to X \mid_n Y_n ... \mid_1 Y_1 
                $
                \item $n$ is the \emph{degree} of the rule
                \item If $n=0$, corresponds to application rule
            \end{itemize}
            \item Type raising:
            \begin{itemize}
                \item Turn an atomic category into a complex category so it can participate in higher-order functions
                \item Forward Type Raising: $(T_>)$
                $
                X \to T / (T \backslash X)
                $
                \item Backward Type Raising: $(T_<)$
                $
                X \to T \backslash (T / X)
                $
                \item E.g.:
                \begin{itemize}
                    \item Intransitive $\textrm{S} \backslash \textrm{NP}$ (e.g. walked)
                    \item Transitive $(\textrm{S} \backslash \textrm{NP}) / \textrm{NP}$ (e.g. respected)
                    \item Ditransitive $((\textrm{S} \backslash \textrm{NP}) / \textrm{NP}) / \textrm{NP}$ (e.g. gave)
                \end{itemize}
            \end{itemize}
        \end{itemize}
        \item Operators:
        \begin{itemize}
            \item Backward slash: $X \backslash Y$: "Give me a $Y$ to my left, and I return an $X$", means that function looks for argument to its left
            \item Forward slash: $X / Y$: "Give me a $Y$ to my right, and I return an $X$", means that function looks for argument to its right
            \item Operators need to be read from outside in, e.g. $(\textrm{S} \backslash \textrm{NP}) / \textrm{NP}$:
            \begin{itemize}
                \item Needs $\textrm{NP}$ to its right
                \item Then needs $\textrm{NP}$ to its left
                \item Then produces sentence $\textrm{S}$
            \end{itemize}
        \end{itemize}
        \item Rule instance is obtained by substituting $X, Y, Z, \dots$ by concrete categories, e.g. $\textrm{S, NP, VP}$, etc.
        \item CCGs have finite rules ($2^n$ forward, $2^n$ backward rules) and, thus, of non-terminals but infinitely many rule instances
    \end{itemize}
\end{itemize}
CCG parsing:
\begin{itemize}
    \item Deductive process
    \item General rule of inference:
    $
    \frac{A_1 \quad \dots \quad A_k}{B}
    $
    where $B$ is a consequence of $A_1, \dots, A_k$
    \item Derivation trees:
    \begin{itemize}
        \item Consist of unary and binary branches:
        \begin{itemize}
            \item Unary branches: Lexicon entries
            \item Binary branches: Composition rules:
            \begin{itemize}
                \item Can have primary and secondary input:
                \begin{itemize}
                    \item Primary input: Function of rule
                    \item Secondary input: Argument of rule
                    \item E.g. $X/Y \ Y\beta \to X\beta$ where $X/Y$ is primary input and $Y\beta$ is secondary input
                \end{itemize}
            \end{itemize}
            \item Structure:
            \hl{INSERT IMAGE 2}
        \end{itemize}
    \end{itemize}
\end{itemize}
CKY-style parsing algorithm:
\begin{itemize}
    \item Let $w$ be the sentence to be parsed, $w_i$ be a token in the sentence, and $w[i, j]$ be the substring from $w_{i+1} \dots w_j$, and $w_{ii} = \varepsilon$
    \item Aim: Construct item $[S, 0, n]$
    \item Derivation tree leading to this outcome has internal nodes $[X, i, j]$
    \item Axioms: $[x, i, i+1]$ where $w_{i+1} = x$ is a lexicon entry
    \item Inference rules:
    \begin{itemize}
        \item Forward:
        $
        \frac{[X / Y, i, j] \quad [Y \beta, j, k]}{[X \beta, i, k]} \quad X / Y \quad Y \beta \to X \beta
        $
        \item Backward:
        $
        \frac{[Y \beta, i, j] \quad [X \backslash Y, j, k]}{[X \beta, i, k]} \quad Y \beta \quad X \backslash Y \to X \beta
        $
    \end{itemize}
    \item Challenge: With the composition rule, we can grow the arity of the primary input categories and get exponentially many primary input categories
    \item Solution: Restrict the arity of the categories
\end{itemize}
Polynomial time algorithm:
\begin{itemize}
    \item Arity of categories is bounded by grammar constant $C_g$:
    $[X, i, j]$ where $\textrm{ar}(X) \leq C_g$
    \item Challenge: Categories with arity $> C_g$ can no longer be derived
    \item Solution:
    \begin{itemize}
        \item Introduce new rules that decompose longer derivations into smaller pieces
        \item Derivation context:
        \begin{itemize}
            \item None of the combinatory rules used in $c$ touches $X$, i.e. $c$ may pop and push the argument $Y$, but never touches $X$
            \item For this reason, $c$ is a derivation context and can be used for any category $X$ across multiple derivations
            \item \hl{INSERT IMAGE 3}
        \end{itemize}
        \item New items:
        \begin{itemize}
            \item $[\mid Y, \beta, i, i', j, j']$ where $\text{ar}(Y \beta) \leq C_g$
            \item For any category $X$, if we can build a derivation tree $t'$ with yield $w[i', j']$ and type $X \mid Y$, then we can build $t$ with yield $w[i, j]$ and type $X \beta$
            \item Derivation context $C$ can be combined with any $t'$ with item of form $[X \mid Y, i', j']$
            \item $c$ can have any internal structure, as long as $X$ is untouched
            \item $t'$ can have any internal structure, only positions $i',j'$ and argument $/Y$ matter for combination with $c$
        \end{itemize}
        \item New inference rules:
        \begin{itemize}
            \item Context items are derived when the composition of two categories would result in a category with arity $> C_g$:
            $
            \frac{[X / Y, i, j] \quad [Y \beta, j, k]}{[\mid Y, \beta, i, i, j, k}
            $ 
            where
            \begin{itemize}
                \item $X \mid Y \quad Y\beta \to X\beta$
                \item $\text{ar}(X \beta) > C_g$
            \end{itemize}
            \item For denominator of above equation:
            \begin{itemize}
                \item When the arity of the context is small enough, it can be recombined with the original derivation:
                $
                \frac{[X \mid Y, i', j'] \quad [\mid Y, \beta, i, i', j', j]}{[X \beta, i, j]}
                $ where $\text{ar}(X \beta) \leq C_g$
                \item Contexts can be extended similar to derivation trees:
                $
                \frac{[\mid Y, \beta / Z, i, i', j', j] \quad [Z_\gamma, j, k,]}{[\mid Y, \beta_\gamma, i, i', j', k]}
                $ where $\beta_\gamma$ refers to $\beta$ without $/ Z$ (can be $\varepsilon$) and where 
                \begin{itemize}
                    \item $X / Z \quad Z_\gamma \to X_\gamma$
                    \item $\text{ar}(Y \beta_\gamma) \leq C_g$
                \end{itemize}\\
                resp.
                $
                \frac{[Z_\gamma, i, j] \quad [\mid Y, \beta \backslash Z, j, j', k', k]}{[\mid Y, \beta_\gamma, i, j', k', k]} 
                $ where $\beta_\gamma$ refers to $\beta$ without $/ Z$ (can be $\varepsilon$) and where 
                \begin{itemize}
                    \item $Z_\gamma \quad X \backslash Z \to X_\gamma$
                    \item $\text{ar}(Y \beta_\gamma) \leq C_g$
                \end{itemize}
                \item For denominator of above equations:
                \begin{itemize}
                    \item If the context extended in this way has arity $> C_g$, a new context is derived from the previous context:
                    $
                    \frac{[\mid Y, \beta / Z, i, i', j', j] \quad [Z_\gamma, j, k]}{[\backslash Z, \gamma, i, i, j, k]}
                    $
                    \item When the arity of the extended context is small enough, it can be recombined with the original context:
                    $
                    \frac{[\mid_1 Y, \beta \mid_2 Z, i'', i', j', j''] \quad [\mid_2 Z, \gamma, i, i'', j'', j]}{[\mid_1 Y, \beta, i, i', j', j]}
                    $
                \end{itemize}
            \end{itemize}
        \end{itemize}
    \end{itemize}
    \item Grammar constant $C_g$ is at least as large as maximum arity of category in axioms $= \ell$ (e.g. if "likes" is in axioms, $C_g \geq 2$)
    \item Grammar constant $C_g$ is at least as large as maximal $Y$ (determined by largest arity $a$ in lexicon) and $\beta$ (determined by the maximum degree $n$ of composition rules), since we need to restrict the size of $Y \beta$
    \item Together: $C_g \geq \max \{ \ell, a + n \}$
\end{itemize}
CCG combine syntactic and semantic information when paired with lambda calculus:
\begin{itemize}
    \item E.g.\\
    Mary $:= \textrm{NP} : \textrm{MARY}(x)$\\
    likes $:= (\textrm{S} \backslash \textrm{NP}) / \textrm{NP} : \lambda x.\ \lambda y.\ \textrm{likes}(x, y)$\\
    natural language $:=$ syntax $:$ semantics
    \item If we parse a sentence syntactically, we can derive semantics bottom-up in the same order
    \item hl{INSERT IMAGE 4}
\end{itemize}