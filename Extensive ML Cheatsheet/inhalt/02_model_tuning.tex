\section{Model Tuning}
\subsection*{Hyperparameter tuning approaches}
Nested cross-validation:
\begin{itemize}
    \item Outer loop (model evaluation): Partition data $\mathcal{Z}$ into $K$ equally sized disjoint subsets, of which $1$ fold is testing set and $K-1$ folds are training set
    \item Inner loop (hyperparemeter tuning): Split outer training set into $M$ equally sized disjoint subsets, of which $1$ fold is validation set and $M-1$ folds are training set
    \item For each outer fold, first conduct inner loop
    \item In each inner loop, determine best hyperparameters by averaging performance for each hyperparameter set across all $M$ folds
    \item Then train outer fold with best hyperparameters
    \item Compute final score by averaging performance on outer folds
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\hl{TBA}