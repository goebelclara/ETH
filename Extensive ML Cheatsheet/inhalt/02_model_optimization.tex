\section{Model Optimization}
\subsection*{Gradient Descent}
Numeric optimization procedure

{\color{lightgray}\hrule height 0.001mm}

\emph{Gradient descent} ---
\begin{itemize}
    \item Uses entire training set to evaluate whether new parameter is more optimal than previous one
    \item Slow and less likely to escape local minima due to randomness, but accurate
    \item Algorithm: 
    \begin{enumerate}
        \item Set $\eta > 0$
        \item Randomly initialize $\boldsymbol{\beta_{(t=0)}}$
        \item $\boldsymbol{\beta_{(t+1)}} \leftarrow \boldsymbol{\beta_{(t)}} - \eta \nabla_{\boldsymbol{\beta}} LO |_{\boldsymbol{\beta} = \boldsymbol{\beta_{(t)}}}$
        \item $t \leftarrow t+1$
        \item Repeat 3 and 4 until $\nabla_{\boldsymbol{\beta}} LO = 0$
    \end{enumerate}
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Stochastic gradient descent} ---
\begin{itemize}
    \item Uses only one training sample or mini-batch to evaluate whether new parameter is more optimal than previous one
    \item Fast and more likely to escape local minima due to randomness, but represents an approximation  
    \item Algorithm: 
    \begin{enumerate}
        \item Set $\eta > 0$
        \item Randomly initialize $\boldsymbol{\beta_{(t=0)}}$
        \item Shuffle training data and initialize $i \leftarrow 1$
        \item $\boldsymbol{\beta_{(t+1)}} \leftarrow \boldsymbol{\beta_{(t)}} - \eta \nabla_{\boldsymbol{\beta}} LO \textrm{ for observation i } |_{\boldsymbol{\beta} = \boldsymbol{\beta_{(t)}}}$
        \item $t \leftarrow t+1$
        \item $i \leftarrow i+1$
        \item Repeat 4 to 6 until $i = n+1$
        \item Repeat 2 to 6 until $\nabla_{\boldsymbol{\beta}} LO = 0$
    \end{enumerate}
    \item Justification for SGD is given by \emph{Robbins-Monro algorithm} which iteratively find the root (or zero) of an unknown function when only noisy observations of the function are available:
    \begin{itemize}
        \item Algorithm:
        \begin{enumerate}
            \item Choose learning rates $\eta_1, \eta_2, ...$, typically decreasing over time
            \item Randomly initialize $\boldsymbol{\beta_{(t=0)}}$
            \item $\boldsymbol{\beta_{(t+1)}} \leftarrow \boldsymbol{\beta_{(t)}} - \eta \nabla_{\boldsymbol{\beta}} LO|_{\boldsymbol{\beta} = \boldsymbol{\beta_{(t)}}}$ where $LO$ is noisy
        \end{enumerate}
        \item For convergence:
        \begin{itemize}
            \item $\sum_{t=1}^\infty \eta_t = \infty$ to ensure sufficient exploration
            \item $\sum_{t=1}^\infty \eta_t^2 \leq \infty$ to avoid overly large updates
            \item Then, $lim_{t \rightarrow \infty} p( | y_t - y | > \epsilon ) = 0$ for any $\epsilon > 0$
        \end{itemize}
    \end{itemize}
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Hyperparameters} ---
\begin{itemize}
    \item Learning rate $\eta$: Determines step size, if too small algorithm is slow to converge, if too large algorithm may diverge
    \item Batch size $b$: Number of samples from training set used to evaluate optimality of $\boldsymbol{\beta}$ at each step
    \item Epoch: Number of times model works through entire training set. Every epoch, $\boldsymbol{\beta}$ is updated $n/b$ times
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Modifications} ---
\begin{itemize}
    \item Data should be standardized resp. scaled, otherwise the gradient of the largest predictor dominates the gradient of the loss function, leading to uneven updating of $\boldsymbol{\beta}$ and slow convergence
    \item A momentum term can be added to the updating function to ensure smooth updating of $\boldsymbol{\beta}$: $\boldsymbol{\beta_{(t+1)}} \leftarrow \boldsymbol{\beta_{(t)}} - \eta \nabla_{\boldsymbol{\beta}} LO |_{\boldsymbol{\beta} = \boldsymbol{\beta_{(t)}}} + \alpha(\boldsymbol{\beta_{(t)}} - \boldsymbol{\beta_{(t)-1}})$
    \item For stochastic gradient descent, a smoothing step can be added because stochastic gradient descent hovers around desired solution: $\hat{\boldsymbol{\beta}}_{(t+1)} \leftarrow \frac{1}{L+1} \sum_{j=t-L}^t \boldsymbol{\beta_{(t)}}$
\end{itemize}