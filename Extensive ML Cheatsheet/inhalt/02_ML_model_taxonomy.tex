\section{Model Taxonomy}
\subsection*{Active Learning}

\emph{Active learning} ---
\begin{itemize}
    \item Assume:
    \begin{itemize}
        \item Domain space $\mathcal{X}$ 
        \item Sample space $S \subseteq \mathcal{X}$
        \item Labeled data $D_{n-1} {(x_i, y_i)}_{i < n}$
        \item Target space $\mathcal{A} \subseteq \mathcal{X}$
        \item We estimate $y_x = f_x + \epsilon_x$
    \end{itemize}
    \item We aim to find the next $x_n$ that gives us the most information about $f$ in $\mathcal{A}$
    \item Information gain can be quantified as maximizing the conditional mutual information between $y_x$ and $f$: $IG [ f_x; y_x | D_{n-1} ] = H(y_x | D_{n-1}) - H(y_x | f_x, D_{n-1})$ where $H(y_x | D_{n-1})$ is the uncertainty about $y_x$ before labeling $x_n$ and $H(y_x | f_x, D_{n-1})$ is the uncertainty about $y_x$ after labeling $x_n$. We want to minimize the latter, i.e. we want to maximize the delta between the former and the latter
    \item We pick $x_n = argmax_{x \in S} IG [ f_x; y_x | D_{n-1} ]$ 
    \item To find a closed-form solution, we assume that $f$ is a Gaussian process with a known mean and kernel function:
    \begin{itemize}
        \item $f \sim \mathcal{G}\mathcal{P} (\mu, k)$
        \item $\boldsymbol{f} = (f_{x_1}, f_{x_2}, ...) \sim \mathcal{N} (\boldsymbol{\mu}, \boldsymbol{\Sigma})$ where elements in mean vector are $\mu_i = \mu(x_i)$ and elements in covariance matrix are $\Sigma_{ij} = k(x_i,x_j)$
    \end{itemize}
    \item Under this assumption, we can show that $IG [ f_x; y_x | D_{n-1} ] = \frac{1}{2} log( \frac{ \mathbb{V} (y_x | D_{n-1}) }{ \mathbb{V} (y_x | f_x, D_{n-1}) } )$\\
    Proof:
    \begin{itemize}
        \item Gaussian entropy of $a|B$ given by: $H(a|B) = - \int p(a|B) log(p(a|B)) da = - \mathbb{E} [ log \mathcal{N}(\mu, \sigma) ] = - \mathbb{E} [ log ((2 \pi \sigma^2)^{-1/2} exp ( - \frac{ (x-\mu)^2 }{ 2 \sigma^2 } )) ] = \frac{1}{2} log (2 \pi \sigma^2) + \frac{1}{2\sigma^2} \mathbb{E}[ (x-\mu)^2 ] = \frac{1}{2} log(2 \pi \sigma^2) + \frac{1}{2} \times 1 = \frac{1}{2} log(2 \pi \sigma^2) + \frac{1}{2} log(e) = \frac{1}{2} log(2 \pi e \sigma^2) $
        \item Plugging this in, we get: $H(y_x | D_{n-1}) - H(y_x | f_x, D_{n-1}) = \frac{1}{2} log(2 \pi e  \mathbb{V}(y_x | D_{n-1})) - \frac{1}{2} log(2 \pi e \mathbb{V}(y_x | f_x, D_{n-1})) = \frac{1}{2} log( \frac{\mathbb{V}(y_x | D_{n-1})}{\mathbb{V}(y_x | f_x, D_{n-1})} )$ 
    \end{itemize}
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Safe Bayesian learning} ---
\begin{itemize}
    \item Bayesian approach to active learning
    \item Assume:
    \begin{itemize}
        \item We have stochastic process $f^*$
        \item We can iteratively choose points $x_1, ..., x_{n-1} \in \mathcal{X}$ and observe $y_i = f^*(x_1), ..., y_{n-1} = f^*(x_{n-1})$
        \item Points should lie in safe area $S^*$ which is the set of $x \in \mathcal{X}$ such that another stochastic process $g^*(x) \geq 0$
        \item For chosen points, we can also observe $z_i = g^*(x_1), ..., z_{n-1} = g^*(x_{n-1})$ which are measurements of confidence, indicating high confidence when above $0$
    \end{itemize}
    \item We aim to find estimates of sample space $S$ and target space $\mathcal{A}$
    \item To do so, we fit a Gaussian process on observed $\{(x_i,y_i)\}_{i<n}$ and $\{(x_i,z_i)\}_{i<n}$. Gaussian process over $f$ and $g$ induces two bounds respectively, which provide the $95\%$ confidence interval of $\mathbb{E}[f(x)]$ resp. $\mathbb{E}[g(x)]$:
    \begin{itemize}
        \item Upper bound function $u_n^f(x)$ resp. $u_n^g(x)$
        \item Lower bound function $l_n^f(x)$ resp. $l_n^g(x)$
    \end{itemize}
    \item Gaussian process over $g$ allows to derive pessimistic and optimistic estimate of safe area:
    \begin{itemize}
        \item Pessimistic: $S_n = \{x: l_n^g(x) \geq 0\}$
        \item Optimistic: $\hat{S}_n = \{x: u_n^g(x) \geq 0\}$
    \end{itemize}
    \item We then gather estimates, where upper bound of $f$ lies above baseline set by maximum value of lower bound of $f$: $\mathcal{A}_n = \{x \in \hat{S}_n : u_n^f(x) \geq max_{x' \in S_n} l_n^f(x')\}$
    \item We can then perform active learning with sample space $S = S_n$ and target space $\mathcal{A} = \mathcal{A}_n$
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Batch active learning} ---
\begin{itemize}
    \item Variant of active learning
    \item Assume:
    \begin{itemize}
        \item Domain space $\mathcal{X}$ and distribution $P$ over $\mathcal{X}$
        \item Oracle to unknown function $f: \mathcal{X} \rightarrow \mathcal{Y}$
        \item Population set $\mathcal{X} = \{x_1, ..., x_m\} \subseteq \mathcal{X}$
        \item Budget $b \leq m$
    \end{itemize}
    \item We aim to find next batch of data points $L \subseteq \mathcal{X}$ subject to $|L| = b$ that gives us the most information
    \item Suppose we know $Z = \{ (x,f(x)): x \in L \}$
    \item 1-nearest-neighbor classifier $\hat{f}$ is fitted to $Z$
    \item Let $B_\delta(x) = \{ x' \in \mathcal{X}: \| x - x' \| \leq \delta \}$ be the set of sufficiently close points to $x$
    \begin{itemize}
        \item We consider $B_\delta(x)$ pure if $f$ yields same results for all of $B_\delta(x)$
    \end{itemize}
    \item Impurity of $\delta$ is given by $\hat{\pi}(\delta) = P(\{{x \in \mathcal{X}: B_\delta(x) \textrm{ is not pure}}\})$
    \item Let  $C(L,S) = \bigcup_{x \in L} B_\delta(x)$ be the union of all sets B
    \begin{itemize}
        \item $C = C_r \cup C_w = \{x \in C: \hat{f}(x) = f(x)\} \cup \{x \in C: \hat{f}(x) \neq f(x)\}$
    \end{itemize}
    \item We have $C_w \subseteq \{{x \in \mathcal{X}: B_\delta(x) \textrm{ is not pure}}\}$. Then, $P(C_w) \leq \hat{\pi}(\delta)$
    \item $\{x: \hat{f}(x) \neq f(x)\} \subseteq C_w \cup C_r^C \subseteq \{{x \in \mathcal{X}: B_\delta(x) \textrm{ is not pure}}\} \cup C^C$
    \item Then, we have $\mathcal{R}(\hat{f}) = P(\hat{f}(x) \neq f(x) \leq \hat{\pi}(\delta) + 1-P(C)$
    \item We need to choose $L$ and $\delta$ such that $\mathcal{R}(\hat{f})$ is minimized
    \item We approach this by minimizing the upper bound, by picking $\delta$ and choosing C that maximizes $P(C)$:
    $argmax_{L \subseteq \mathcal{X}, |L| = b} P(\bigcup_{x \in L} B_\delta(x))$
    \item Two challenges:
    \begin{enumerate}
        \item We don't know the distribution
        \item Problem is NP-hard
    \end{enumerate}
    \item We address 1) by using the empirical distribution induced by $X$. Then, we have: $argmax_{L \subseteq \mathcal{X}, |L| = b} \frac{1}{|X|} | \{ x': \|x'-x\| \leq \delta, \textrm{ for some } x \in L \} |$
    \item We address 2) with greedy algorithm:
    \begin{itemize}
        \item Input: $x \subseteq \mathcal{X}, b \in \mathbb{N}$
        \item Output: $L \subseteq X \textrm{ of size } b$
    \end{itemize}
    \begin{enumerate}
        \item $G = (x,E)$ where $E = \{ (x,x') : \| x - x' \| \leq \delta \}$
        \item $L = \varnothing$
        \item For $i = 1, ..., b$:
        \begin{enumerate}
            \item $\hat{x} \leftarrow argmax_{x \in \mathcal{X}} | \{ x': (x,x') \in E, x \in \mathcal{X} \} |$
            \item $L \leftarrow L \cup {\hat{x}}$
            \item $E \leftarrow E - (\{ \hat{x} \} \times (B_\delta(\hat{x}) \cap x))$
        \end{enumerate}
        \item Return $L$
    \end{enumerate}
\end{itemize}

{\color{black}\hrule height 0.001mm}

\subsection*{Ensemble Methods}

\emph{Motivation} ---
\begin{itemize}
    \item Let $\hat{f}_1(x), ..., \hat{f}_B(x)$ be estimators
    \item When averaging estimators...
    \begin{itemize}
        \item Average remains unbiased, if all estimators are unbiased\\
        Proof:\\
        Bias $= \mathbb{E} [ \hat{f}(x) ] - \mathbb{E} [ y | x ] = \frac{1}{B} \sum_{i=1}^B \mathbb{E} [ \hat{f}_i(x) ] - \mathbb{E} [ y | x ] = \frac{1}{B} \sum_{i=1}^B \textrm{ bias}(\hat{f}_i(x))$
        \item Variance is reduced by a factor of $\frac{1}{B}$, if the estimators have similar variance and no covariance\\
        Proof:
        \begin{itemize}
            \item Variance $= \mathbb{E} [ \hat{f}(x) - \mathbb{E} [ \hat{f}(x) ]]^2 = \mathbb{E} [ \frac{1}{B} \sum_{i=1}^B \hat{f}_i(x) - \frac{1}{B} \sum_{i=1}^B \mathbb{E} [ \hat{f}_i(x) ] ]^2 = \mathbb{E} [ \frac{1}{B} \sum_{i=1}^B (\hat{f}_i(x) - \mathbb{E} [ \hat{f}_i(x) ]) ]^2 = \frac{1}{B^2} \sum_{i=1}^B \mathbb{V} [ \hat{f}_i(x) ] + \frac{1}{B^2} \sum \sum_{i \neq j =1}^B \textrm{ Cov}[ \hat{f}_i(x), \hat{f}_j(x) ] $
            \item Assuming variance are similar ($\approx \sigma^2$) and covariances are small ($\approx 0$), we get: Variance $= \frac{1}{B^2} \sum_{i=1}^B \sigma^2 = \frac{1}{B^2} B \sigma^2 = \frac{\sigma^2}{B}$
        \end{itemize}
    \end{itemize}
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Requirements} --- 
Diversity of estimators, to reduce covariance. Achieved by:
\begin{itemize}
    \item Different subsets of data for each estimator, e.g. via bootstrapping
    \item Different features for each estimators
    \item Decorrelating estimators during training
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Variants} --- 
\begin{itemize}
    \item Regression: Average output of all estimators: $\hat{r}_B(x) = \frac{1}{B} \sum_{b=1}^B r_b(x) )$ 
    \item Classification: Majority or weighted voting:
    $\hat{c}_B(x) = sgn( \sum_{b=1}^B \alpha_b c_b(x) )$ with majority voting if $\alpha = 1$
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Bootstrap Aggregating (Bagging)} --- 
\begin{itemize}
    \item Algorithm
    \begin{enumerate}
        \item For $b = 1, ..., B$:
        \begin{enumerate}
            \item Hold out $\frac{1}{3}$ of sample
            \item Construct $Z^{*}_b = b^{th}$ bootstrap sample from remaining $\frac{2}{3}$ of sample
            \item Construct estimator $f_b$ based on $Z^{*}_b$ 
        \end{enumerate}
        \item Return $\hat{f}_B(x) =$ weighted average of $f_1(x), ..., f_B(x)$
        \item Calculate out-of-bag error on held out sample
    \end{enumerate}
\end{itemize}
If desired: Estimators can be constructed in multiple function classes $f^{'}, f^{''}, ...$ and set of estimators in the function class, which generates the lowest empirical error, is returned

{\color{lightgray}\hrule height 0.001mm}

\emph{Random Forest} --- 
\begin{itemize}
    \item Algorithm:
    \begin{enumerate}
        \item Generate multiple training sets via bootstrapping
        \item Construct multiple decision trees based on the generated training sets, where each tree selects a random set of features at each split via bootstrapping
        \begin{itemize}
            \item Classification: Choose $m = \sqrt{k}$ predictors at each split
            \item Regression: Choose $m = \frac{k}{3}$ predictors at each split
        \end{itemize}
        \item Generate prediction by averaging or voting on trees
        \item Calculate out-of-bag error
    \end{enumerate}
    \item 2 sources of randomness:
    \begin{itemize}
        \item Each tree trained on bootstrap sample of instances
        \item At each split, bootstrap sample of features is considered
    \end{itemize}
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{AdaBoost} --- 
Algorithm:
\begin{enumerate}
    \item Each instance weight is initially $w_i = \frac{1}{n}$
    \item Train first classifier $\hat{c}^{(1)}$ generating output $\hat{y}^{(1)}$
    \item Calculate weighted error rate of $j^{th}$ classifier: $r^{(j)} = \frac{ \sum_{i=1}^n w_i \mathbb{I}_{\{ \hat{y}_i^{(j)} \neq y_i \}} }{ \sum_{i=1}^n w_i }$
    \item Calculate classifier weight, which is higher, if the classifier has a lower error rate: $\alpha^{(j)} = \eta log( \frac{1-r^{(j)}}{r^{(j)}} )$
    \item Update instance weights: For $i = 1, ..., n$: 
    \begin{align*}
    w_i = 
    \left\{
        \begin{aligned}
             & w_i \quad & \hat{y}_i^{(j)} = y_i \\
             & w_i e^{\alpha^{(j)}} \quad & \hat{y}_i^{(j)} \neq y_i
        \end{aligned}
    \right.
    \end{align*}
    \item Normalize instance weights: $w_i = \frac{w_i}{\sum_{i=1}^n w_i}$
    \item Continue by training next classifier
    \item ...
    \item Generate prediction: $\hat{y}(x) = argmax_k \sum_{j=1}^B \alpha_j \mathbb{I}_{\{ \hat{c}^{(j)}(x) = k \}}$
\end{enumerate}
AdaBoost is an additive logistic model that minimizes the exponential loss function:
\begin{itemize}
    \item Exponential loss function: $\mathbb{E} [ e^{-y F(x)} ] = p(y=1 | x) e^{-F(x)} + p(y=-1 | x) e^{F(x)}$
    \item Minimizer of exponential loss function is the log-odds: $\mathbb{E} [ e^{-y F(x)} ]$ is minimized at $\frac{ \partial \mathbb{E} [ e^{-y F(x)} ] }{ \partial F(x) } = \frac{1}{2} log ( \frac{ p(y=1 | x) }{ p(y=-1 | x) } ) = F(x) = 0 $
    \item Then, $p(y=1 | x) = \frac{ e^{F(x)} }{  e^{-F(x)} +  e^{F(x)} }$
    \item Log-odds minimizer corresponds to the AdaBoost minimizer, since AdaBoost models the final output as a sum of classifiers: $log ( \frac{ p(y=1 | x) }{ p(y=-1 | x) } ) = \sum_{j=1}^B \alpha_j \hat{c}^{(j)}(x) = F(x)$
\end{itemize}
AdaBoost as gradient descent:
\begin{itemize}
    \item Discrete AdaBoost model can be viewed as performing gradient descent on an additive logistic model
    \item Cost function: Minimize $J(F) = \mathbb{E} [ e^{-y F(x)} ]$ where $F(x)$ is the combined classifier, consisting of multiple weak classifiers
    \item Suppose we consider an improved function $F'(x)$: $F'(x) = F(x) + \alpha c(x)$ where $c(x)$ is a new weak classifier
    \item To approximate $J(F')$ we can perform a Taylor expansion around 0: $J(F') = \mathbb{E} [ e^{-y (F(x) + \alpha c(x))} ] = \mathbb{E} [ e^{-y F(x)} (1 - y \alpha c(x) + \frac{1}{2}\alpha^2) ] + O(\alpha^3)$
    \item To minimize $J(F')$ wrt $c(x)$:
    \begin{itemize}
        \item We define weighted expectation:
        \begin{itemize}
            \item Weights: $w(x,y) = e^{-y F(x)}$
            \item Weighted expectation of $g(x,y)$: $\mathbb{E} [g(x,y) | x] = \frac{ \mathbb{E} [w(x,y) g(x,y) | x] }{ \mathbb{E} [w(x,y) | x] }$
        \end{itemize}
        \item We aim to choose $c(x)$ that maximizes weighted expectation of $g(x,y) = y c(x)$ since this is equivalent to minimizing exponential loss
        \item In $O(\alpha^2)$ this yields: $c(x) =$ \begin{itemize}
            \item $argmin_c = \mathbb{E} [ 1 - y \alpha c(x) + \frac{1}{2}\alpha^2 | x ]$
            \item $argmax_c = \mathbb{E} [ y c(x) | x ]$
            \item $= 1$ if $\mathbb{E} [y|x] = 1 \times p(y=1|x) + (-1) \times p(y=-1|x) > 0$\\
            $= -1$ otherwise
        \end{itemize}
        \item We can approximate the exponential via the quadratic loss. Then, we have: $\frac{1}{2} \mathbb{E} [ (y - c(x))^2 ] - 1 = \mathbb{E} [y^2 - 2yc(x) + c(x)^2] \frac{1}{2} - 1 = \mathbb{E} [1 - 2yc(x) + 1] \frac{1}{2} - 1 =  - \mathbb{E} [yc(x)]$
        \item Then, we have:
        \begin{itemize}
            \item $argmin_c = -\mathbb{E} [ y c(x) | x ]$
            \item $argmax_c = \mathbb{E} [ y c(x) | x ]$
        \end{itemize}
        \item Minimizing the quadratic approximation leads to a Newton-like step for choosing $c(x)$, making it a weighted least squares choice of $c(x)$
    \end{itemize}
    \item To minimize $J(F')$ wrt $\alpha$:
    \begin{itemize}
        \item $\alpha^{*} = argmin_\alpha \mathbb{E} [ e^{-y \alpha c(x)} ] = e^\alpha \mathbb{E} [ \mathbb{I}_{\{ y \neq c(x) \}} ] + e^{-\alpha} \mathbb{E} [ \mathbb{I}_{\{ y = c(x) \}} ] = \frac{1}{2} log(\frac{1-err}{err})$ where $err = \mathbb{E} [ \mathbb{I}_{\{ y \neq c(x) \}} ]$
    \end{itemize}
    \item Combination yields AdaBoost update:
    \begin{itemize}
        \item $F'(x) \leftarrow F(x) + \alpha^{*} c(x) = F(x) + \frac{1}{2} log( \frac{1-err}{err} )$
        \item $w(x,y) \leftarrow w(x,y) \times e^{-\alpha^{*} y c(x)} = w(x,y) \times e^{\alpha^{*} (2 \mathbb{I}_{\{ y \neq c(x) \}} - 1)} = w(x,y) \times e^{log(\frac{1-err}{err}) \mathbb{I}_{\{ y \neq c(x) \}}} \times e^{-\alpha^{*}}$ where $e^{-\alpha^{*}}$ is a constant
    \end{itemize}
\end{itemize}