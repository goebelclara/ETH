\section{Diffusion Models}
\subsection*{Description}
\emph{Task} --- Generate new samples

{\color{black}\hrule height 0.001mm}

\subsection*{Formulation}
\emph{Formulation} --- 
\begin{itemize}
    \item Model architecture: 
    \begin{itemize}
        \item VAE for compression: Compress original data into latent space
        \item Forward diffusion: Gradually add Gaussian noise to latent representation
        \item Reverse diffusion: Gradually remove noise from latent representation, potentially guided by condition (e.g. text input), until latent representation is restored
        \item Decoder: Decodes latent representation back to original data
    \end{itemize}
    \item Generally implemented as a U-Net
\end{itemize}

{\color{black}\hrule height 0.001mm}

\subsection*{Components}
\emph{Forward diffusion} --- 
\begin{itemize}
    \item Real data: $x_0 \sim p(x)$
    \item Gaussian noise: $x_T \sim \mathcal{N}(0,\sigma^2 \boldsymbol{I})$
    \item $x_0 \rightarrow x_1 \rightarrow ... \rightarrow x_T$
    \item Stochastic differential equation: $dx = f(x,t)dt + g(t) dW$
    \begin{itemize}
        \item $x:$ Variable being diffused
        \item $f(x,t):$ Deterministic \emph{drift term}: Represents the mean rate of change of $x$ at time $t$
        \item $g(t):$ \emph{Diffusion coefficient}: Function that scales the magnitude of the noise
        \item $dW:$ Random \emph{Wiener process resp. Brownian motion}: Represents random fluctuations
        \item Function shows how $x$ changes over time due to deterministic and random influences
    \end{itemize}
    \item Two transitions:
    \begin{itemize}
        \item $q(x_t | x_{t-1}) \sim \mathcal{N}(x_t | \sqrt{1-\beta} x_{t-1}, \beta_t \boldsymbol{I} )$
        \begin{itemize}
            \item $\beta_t:$ Added noise
        \end{itemize}
        \item $q(x_t | x_0) \sim \mathcal{N}(x_t | \sqrt{\bar{\alpha}_t} x_0, (1-\bar{\alpha}_t) \boldsymbol{I} )$
        \begin{itemize}
            \item $\alpha_t = 1-\beta_t:$ Retained signal
            \item $\bar{\alpha}_t = \prod_{s \leq t} \alpha_t:$ Cumulative retained signal until $t$
            \item $1-\bar{\alpha}_t:$ Cumulative added noise until $t$
        \end{itemize}
    \end{itemize}
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Reverse diffusion} --- 
\begin{itemize}
    \item $x_T \rightarrow x_{T-1} \rightarrow ... \rightarrow x_0$
    \item Stochastic differential equation: $dx = [f(x,t) - g(t)^2 \nabla_x \log p(x,t)]dt + g(t) dW$
    \begin{itemize}
        \item $x:$ Variable being diffused
        \item $f(x,t):$ Deterministic \emph{drift term}: Represents the mean rate of change of $x$ at time $t$
        \item $\nabla_x \log p(x,t):$ Score function: Captures gradient of log probability of system state at time $t$. Guides the system to reverse the noise by pulling the state $x$ to higher-probability regions.
        \item $g(t)^2:$ Function that scales the impact of the score function
        \item $g(t):$ Function that scales the magnitude of the noise
        \item $dW:$ Random \emph{Wiener process resp. Brownian motion}: Represents random fluctuations
        \item Function shows how $x$ changes over time due to deterministic and random influences
    \end{itemize}
    \item To approximate the score function resp. predict the noise, we train a model $f_\theta(x,t) \approx \nabla_x \log p(x,t)$:
    \begin{itemize}
        \item $f_\theta(x,t): \mathcal{X} \times [0,1] \rightarrow \mathcal{X}$, where $t \in [0,1]$ and $x \sim p(x)$
        \item Proof that $f_\theta(x,t)$ approximates the score function and predicts the noise:
        \begin{itemize}
            \item Gradient of log probability of Gaussian is: $\frac{-(x_t - \mu)}{\sigma^2}$
            \item Therefore and based on $q(x_t | x_0)$ from forward diffusion, score is given by: $\nabla_x \log p(x,t) = \frac{-(x_t - \sqrt{\bar{\alpha}_t} x_0)}{(1-\bar{\alpha}_t)}$
            \item $x_0$ is unknown and must be estimated as $\hat{x}_0$
            \item Then, we have $\nabla_x \log p(x,t) = \frac{-(x_t - \sqrt{\bar{\alpha}_t} \hat{x}_0)}{(1-\bar{\alpha}_t)}$, where $f_\theta(x,t) = (x_t - \sqrt{\bar{\alpha}_t} \hat{x}_0)$, which is the predicted noise
            \item From this we see, that $f_\theta(x,t)$ is equal to $\nabla_x \log p(x,t)$ up to a scaling factor $-\frac{1}{(1-\bar{\alpha}_t)}$
        \end{itemize}
        \item $f_\theta(x,t)$ is trained to minimize the difference between the added and predicted noise: $min_\theta \mathbb{E}_{x,\epsilon,t} \| \epsilon - f_\theta(x + \sigma_t \epsilon, t) \|^2$
    \end{itemize}
    \item Reconstruction formula: $x_{t-1} = \frac{1}{\sqrt{\alpha_t}} (x_t - \frac{1-\alpha_t}{\sqrt{1- \bar{\alpha}_t}} \epsilon_\theta(x_t,t)) + \sigma_tz$
    \begin{itemize}
        \item $\frac{1}{\sqrt{\alpha_t}}:$ Scaling factor
        \item $\frac{1-\alpha_t}{\sqrt{1- \bar{\alpha}_t}} \epsilon_\theta(x_t,t):$ Predicted noise
        \item In formula, predicted noise is subtracted from $x_t$, after which a small amount of random noise $\sigma_tz$ is re-introduced to maintain stochasticity
    \end{itemize}
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Compression} --- 
\begin{itemize}
    \item Motivation: Images often have high dimensionality, which can be easily compressed, since there are many redundant dimensions that do not contain unique information
    \item VAE first encodes $x$ into latent representation $z$ and then decodes $z$ into original representation $\hat{x}$
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{Conditional denoising} --- 
\begin{itemize}
    \item Extension of diffusion model to include additional condition $y$, e.g. a text prompt, and guiding the denoising process such that the generated sample $\hat{x}$ aligns with $y$
    \item VAE first encodes $x$ into latent representation $z$ and then decodes $z$ into original representation $\hat{x}$
    \item To approximate the score function resp. predict the noise, we train a model $f_\theta(x,y,t) \approx \nabla_x \log p(x,t)$:
    \begin{itemize}
        \item $f_\theta(x,y,t): \mathcal{X} \times \mathcal{Y} \times [0,1] \rightarrow \mathcal{X}$, where $t \in [0,1]$ and $x \sim p(x)$
        \item $f_\theta(x,y,t)$ is trained to minimize the difference between the added and predicted noise: $min_\theta \mathbb{E}_{x,y,\epsilon,t} \| \epsilon - f_\theta(x + \sigma_t \epsilon, y, t) \|^2$
    \end{itemize}
    \item Condition $y$ is injected via:
    \begin{itemize}
        \item Concatenating $y$ with latent feature maps
        \item Cross-attention:
        \begin{itemize}
            \item Dynamically weighs importance of different input features by paying attention to specific regions of the feature map based on guidance
            \item Queries from latent feature map $z$
            \item Keys and values from condition $y$
            \item Dimensionality analysis:
            \begin{itemize}
                \item Latent feature map $z$: $B \times C \times h \times w$
                \item Text embedding $y$: $B \times M \times D_E$
                \item $W_q$: $F \times C \times D_K \times f_h \times f_w$
                \item $Q$: $B \times F \times h \times w \times D_K$
                \item $W_k$: $F \times D_E \times D_K$
                \item $K$: $B \times F \times M \times D_K$
                \item $W_v$: $F \times D_E \times D_V$
                \item $V$: $B \times F \times M \times D_V$
                \item $P$ and $S$: $B \times F \times h \times w \times M$
                \item $SV$: $B \times F \times h \times w \times D_V$
            \end{itemize}
            \item When $y$ is text embedding, but $z$ is image embedding, we need \emph{CLIP resp. contrastive learning} to match text and image:
            \begin{itemize}
                \item Let true caption embeddings be $[t_1, ..., t_N]$ and corresponding image embeddings be $[i_1, ..., i_N]$
                \item Matrix representation given by
                $
                \begin{bmatrix}
                t_1 \cdot i_1 & ... & t_N \cdot i_1\\
                ... & ... & ...\\
                t_1 \cdot i_N & ... & t_N \cdot i_N\\
                \end{bmatrix}
                $
                \item Aim is to maximize similarity between image and its true caption on diagonal, but minimize other pairs
            \end{itemize}
        \end{itemize}
        \item Spatial transformer: Dynamically transforms spatial properties of an input (e.g. scale, rotation, location) to focus on most relevant parts
    \end{itemize}
\end{itemize}

{\color{lightgray}\hrule height 0.001mm}

\emph{U-Net} --- 
\begin{itemize}
    \item Architecture:
    \begin{itemize}
        \item CNN (encoder): Downsamples image to create compressed, low-dimensional representation, uses pooling and ReLu
        \item Inverted CNN (decoder): Upsamples compressed, low-dimensional representation to generate image, uses upsampling and softmax
    \end{itemize}
    \item Key operations:
    \begin{itemize}
        \item Skip connections going directly from encoder to decoder
        \item Convolution operation: Apply spatial filters to extract spatial features (e.g. edges, textures, patterns)
        \item Down- and upsampling: Reduce spatial dimensions of input (e.g. via max-pooling, strided convolutions) resp. reconstruct spatial resolution (e.g. via transposed convolution, interpolation), low-level details (e.g. edges) captured at shallow layers, high-level patterns (e.g. objects) captured at deeper layers
    \end{itemize}
\end{itemize}